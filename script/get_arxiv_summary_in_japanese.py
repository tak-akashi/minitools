import os
import requests
import json
import feedparser
import ollama
from typing import List, Dict, Tuple
from datetime import datetime, timedelta
import pytz
import argparse
import logging
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

def setup_logger() -> logging.Logger:
    """ãƒ­ã‚¬ãƒ¼ã®è¨­å®š"""
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©
    log_dir = Path("outputs/logs")
    log_dir.mkdir(parents=True, exist_ok=True)
    file_handler = logging.FileHandler(log_dir / "arxiv.log", mode="a")
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    return logger

logger = setup_logger()



NOTION_API_KEY = os.getenv("NOTION_API_KEY")
DATABASE_ID = os.getenv("NOTION_DB_ID")
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")


def search_arxiv(queries: List[str], start_date: str, end_date: str, max_results: int) -> List[Dict[str, str]]:
    """
    arXiv APIã‚’ä½¿ç”¨ã—ã¦è«–æ–‡ã‚’æ¤œç´¢
    
    Args:
        queries: æ¤œç´¢èªã®ãƒªã‚¹ãƒˆ
        start_date: æ¤œç´¢é–‹å§‹æ—¥ï¼ˆYYYYMMDDå½¢å¼ï¼‰
        end_date: æ¤œç´¢çµ‚äº†æ—¥ï¼ˆYYYYMMDDå½¢å¼ï¼‰
        max_results: å–å¾—ã™ã‚‹æœ€å¤§çµæœæ•°
    
    Returns:
        æ¤œç´¢çµæœã®è«–æ–‡æƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    url = "http://export.arxiv.org/api/query"
    search_query = " AND ".join(queries)
    
    params = {
        "search_query": f"all:{search_query} AND submittedDate:[{start_date}000000 TO {end_date}235959]",
        "start": 0,
        "max_results": max_results,
        "sortBy": "submittedDate",
        "sortOrder": "ascending",
    }
    
    response = requests.get(url, params=params)
    feed = feedparser.parse(response.content)
    
    papers = []
    for entry in feed.entries:
        title = entry.title.replace("\n", "")
        pdf_url = next((link.href for link in entry.links if link.get('title') == 'pdf'), None)
        
        if pdf_url:
            papers.append({
                "title": title,
                "updated_date": entry.updated,
                "published_date": entry.published,
                "summary": entry.summary,
                "pdf_url": pdf_url
            })
    
    return papers


def summarize_paper_briefly(title: str, summary: str, model="gemma3:27b") -> str:
    """
    è«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨è¦ç´„ã‹ã‚‰ç°¡æ½”ãªè¦ç´„ã‚’ç”Ÿæˆ
    """
    prompt = f"""ä»¥ä¸‹ã®è«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨è¦ç´„ã‚’1ã€œ2æ–‡ã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚
    
ã‚¿ã‚¤ãƒˆãƒ«: {title}
è¦ç´„: {summary}

ç°¡æ½”ãªè¦ç´„:"""
    
    response = ollama.chat(model=model, messages=[
        {"role": "user", "content": prompt}
    ])
    return response["message"]["content"].strip()


def translate_to_japanese_with_ollama(text: str, model: str = "gemma3:27b") -> str:
    """
    ollamaã‚’ä½¿ç”¨ã—ã¦æ—¥æœ¬èªã«ç¿»è¨³
    
    Args:
        text: ç¿»è¨³ã™ã‚‹è‹±èªã®ãƒ†ã‚­ã‚¹ãƒˆ
        model: ä½¿ç”¨ã™ã‚‹ollamaãƒ¢ãƒ‡ãƒ«
    
    Returns:
        æ—¥æœ¬èªã«ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    response = ollama.chat(
        model=model,
        messages=[{
            "role": "user",
            "content": f"ä»¥ä¸‹ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ã€‚\n\n{text}"
        }]
    )
    return response["message"]["content"].strip()


def add_to_notion(
    title: str,
    published_date: str,
    updated_date: str,
    summary: str,
    translated_summary: str,
    url: str
) -> bool:
    """
    Notion APIã«ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
    
    Returns:
        ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆTrue
    """
    if not NOTION_API_KEY or not DATABASE_ID:
        logger.error("Notion API key or Database ID not set")
        return True
    
    api_url = "https://api.notion.com/v1/pages"
    headers = {
        "Authorization": f"Bearer {NOTION_API_KEY}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }
    
    data = {
        "parent": {"database_id": DATABASE_ID},
        "properties": {
            "ã‚¿ã‚¤ãƒˆãƒ«": {
                "title": [{"text": {"content": title}}]
            },
            "å…¬é–‹æ—¥": {
                "date": {"start": published_date}
            },
            "æ›´æ–°æ—¥": {
                "date": {"start": updated_date}
            },
            "æ¦‚è¦": {
                "rich_text": [{"text": {"content": summary[:2000]}}]  # Notion API limit
            },
            "æ—¥æœ¬èªè¨³": {
                "rich_text": [{"text": {"content": translated_summary[:2000]}}]
            },
            "URL": {
                "url": url
            }
        }
    }
    
    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            logger.info(f"Added '{title}' to Notion.")
            return False
        else:
            logger.error(f"Failed to add to Notion. Status: {response.status_code}, Response: {response.text}")
            return True
    except Exception as e:
        logger.error(f"Error adding to Notion: {e}")
        return True


def format_slack_message(papers: List[dict], date: str) -> str:
    """
    è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’SlackæŠ•ç¨¿ç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    """
    if not papers:
        return f"*{date}ã®arXivè«–æ–‡*\næœ¬æ—¥ã¯å¯¾è±¡è«–æ–‡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    message = f"*{date}ã®arXivè«–æ–‡ ({len(papers)}ä»¶)*\n\n"
    
    for i, paper in enumerate(papers, 1):
        brief_summary = summarize_paper_briefly(paper['title'], paper['summary'])
        message += f"{i}. *{paper['title']}*\n"
        message += f"   ğŸ“„ {brief_summary}\n"
        message += f"   ğŸ”— <{paper['pdf_url']}|PDF>\n\n"
    
    return message


def send_to_slack(message: str) -> bool:
    """
    Slackã«æŠ•ç¨¿
    """
    if not SLACK_WEBHOOK_URL:
        logger.error("SLACK_WEBHOOK_URL environment variable not set")
        return False
    
    payload = {"text": message}
    
    try:
        response = requests.post(SLACK_WEBHOOK_URL, json=payload)
        if response.status_code == 200:
            logger.info("Successfully sent message to Slack")
            return True
        else:
            logger.error(f"Failed to send to Slack. Status code: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"Error sending to Slack: {e}")
        return False



def process_papers(
    papers: List[Dict[str, str]]
) -> Tuple[int, List[Dict[str, str]]]:
    """
    è«–æ–‡ã‚’å‡¦ç†ã—ã¦Notionã«ä¿å­˜
    
    Returns:
        (ã‚¨ãƒ©ãƒ¼æ•°, å‡¦ç†æ¸ˆã¿è«–æ–‡ãƒªã‚¹ãƒˆ)
    """
    error_count = 0
    processed_papers = []
    
    for i, paper in enumerate(papers, 1):
        logger.info(f"Processing {paper['title']} ({i}/{len(papers)})")
        
        # æ—¥æœ¬èªã«ç¿»è¨³
        translated_summary = translate_to_japanese_with_ollama(paper["summary"])
        
        # Notionã«è¿½åŠ 
        error = add_to_notion(
            paper['title'],
            paper["published_date"],
            paper["updated_date"],
            paper["summary"],
            translated_summary,
            paper['pdf_url']
        )
        
        if error:
            error_count += 1
        
        # å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        processed_paper = paper.copy()
        processed_paper['translated_summary'] = translated_summary
        processed_papers.append(processed_paper)
    
    return error_count, processed_papers


def main(
    queries: List[str],
    start_date: str,
    end_date: str,
    max_results: int,
    send_slack: bool = True
) -> None:
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    logger.info(
        f"Searching max {max_results} papers from {start_date} to {end_date} "
        f"with queries: {queries}"
    )
    
    # è«–æ–‡ã‚’æ¤œç´¢
    papers = search_arxiv(
        queries,
        start_date.replace("-", ""),
        end_date.replace("-", ""),
        max_results
    )
    logger.info(f"Found {len(papers)} papers")
    
    if not papers:
        logger.info("No papers found")
        if send_slack:
            slack_message = format_slack_message([], end_date)
            send_to_slack(slack_message)
        return
    
    # è«–æ–‡ã‚’å‡¦ç†
    error_count, processed_papers = process_papers(papers)
    
    logger.info(
        f"Processed {len(papers) - error_count} papers successfully. "
        f"{error_count} papers failed."
    )
    
    # Slackã«æŠ•ç¨¿
    if send_slack:
        slack_message = format_slack_message(processed_papers, end_date)
        send_to_slack(slack_message)


def parse_args() -> argparse.Namespace:
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ"""
    parser = argparse.ArgumentParser(
        description="arXivã‹ã‚‰è«–æ–‡ã‚’æ¤œç´¢ã—ã€Notionã«ä¿å­˜ã—ã¦Slackã«é€šçŸ¥"
    )
    
    jst = pytz.timezone('Asia/Tokyo')
    yesterday = (datetime.now(jst) - timedelta(days=1)).strftime("%Y-%m-%d")
    
    parser.add_argument(
        '-q', '--queries',
        nargs='+',
        default=["LLM", "(RAG OR FINETUNING OR AGENT)"],
        help="æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆè¤‡æ•°æŒ‡å®šå¯ï¼‰"
    )
    parser.add_argument(
        '-d', '--days_before',
        type=int,
        default=1,
        help="ä½•æ—¥å‰ã‹ã‚‰æ¤œç´¢ã™ã‚‹ã‹"
    )
    parser.add_argument(
        '-b', '--base_date',
        type=str,
        default=yesterday,
        help="åŸºæº–æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰"
    )
    parser.add_argument(
        '-r', '--max_results',
        type=int,
        default=50,
        help="å–å¾—ã™ã‚‹æœ€å¤§è«–æ–‡æ•°"
    )
    parser.add_argument(
        '--no-slack',
        action='store_true',
        help="Slackã¸ã®æŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—"
    )
    
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    
    start_date = (
        datetime.strptime(args.base_date, "%Y-%m-%d") - 
        timedelta(days=args.days_before - 1)
    ).strftime("%Y-%m-%d")
    
    main(
        queries=args.queries,
        start_date=start_date,
        end_date=args.base_date,
        max_results=args.max_results,
        send_slack=not args.no_slack
    )
