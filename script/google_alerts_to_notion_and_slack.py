#!/usr/bin/env python3
"""
Google Alerts to Notion and Slack
GmailçµŒç”±ã§Google Alertsãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—ã—ã€å„ã‚¢ãƒ©ãƒ¼ãƒˆã®å†…å®¹ã‚’æ—¥æœ¬èªè¦ç´„ã¨å…±ã«Notionã«ä¿å­˜ã—ã¦Slackã«é€ä¿¡

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯éå»6æ™‚é–“ã®ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—ï¼ˆå®šæœŸå®Ÿè¡Œæƒ³å®šï¼‰
--dateã§æ—¥ä»˜ã‚’æŒ‡å®šã—ãŸå ´åˆã¯ã€ãã®æ—¥ã®å…¨ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pickle
import base64
import re
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import json
from dataclasses import dataclass
from urllib.parse import urlparse
import pytz
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

import requests
from bs4 import BeautifulSoup
from notion_client import Client
import ollama
from dotenv import load_dotenv
from utils.logger import setup_logger

load_dotenv()

# ã‚¹ã‚³ãƒ¼ãƒ—è¨­å®š
SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']

# Slackè¨­å®š
SLACK_WEBHOOK_URL = os.getenv('SLACK_WEBHOOK_URL_GOOGLE_ALERTS')

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = setup_logger(
    name=__name__,
    log_file="google_alerts.log"
)

@dataclass
class Alert:
    """ã‚¢ãƒ©ãƒ¼ãƒˆæƒ…å ±ã‚’æ ¼ç´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    title: str
    url: str
    source: str
    snippet: str = ""
    japanese_title: str = ""
    japanese_summary: str = ""
    date_processed: str = ""
    article_content: str = ""
    tags: List[str] = None
    
    def __post_init__(self):
        if self.tags is None:
            self.tags = []


class GoogleAlertsProcessor:
    """Google Alertsãƒ¡ãƒ¼ãƒ«ã‚’å‡¦ç†ã—ã¦Notionã«ä¿å­˜ã—ã¦Slackã«é€ä¿¡ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.gmail_service = None
        self.notion_client = None
        self.ollama_client = None
        self.log_lock = threading.Lock()  # ãƒ­ã‚°å‡ºåŠ›ã®åŒæœŸç”¨
        self.setup_clients()
    
    def setup_clients(self):
        """å„ç¨®APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
        # Gmail API
        gmail_service = self._authenticate_gmail()
        if gmail_service is None:
            raise ValueError("Gmail APIã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
        self.gmail_service = gmail_service
        
        # Notion API
        notion_token = os.getenv('NOTION_API_KEY')
        if not notion_token:
            raise ValueError("NOTION_API_KEY(ç’°å¢ƒå¤‰æ•°)ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        self.notion_client = Client(auth=notion_token)
        
        # Ollama Client
        self.ollama_client = ollama.Client()
    
    def safe_print(self, message: str):
        """ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªãƒ­ã‚°å‡ºåŠ›"""
        with self.log_lock:
            logger.info(message)
    
    def extract_tags_from_subject(self, subject: str) -> List[str]:
        """Google Alertsãƒ¡ãƒ¼ãƒ«ã®ä»¶åã‹ã‚‰ã‚¿ã‚°ã‚’æŠ½å‡º"""
        if not subject:
            return ["ãã®ä»–"]
        
        # ä»¶åã‚’å°æ–‡å­—ã«å¤‰æ›ã—ã¦ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†
        subject_lower = subject.lower()
        tags = []
        
        # ã‚¿ã‚°ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ â†’ ã‚¿ã‚°ï¼‰
        tag_mapping = {
            # AIä¸€èˆ¬
            "artificial intelligence": "AIä¸€èˆ¬",
            "ai technology": "AIä¸€èˆ¬", 
            "ai research": "AIä¸€èˆ¬",
            "machine intelligence": "AIä¸€èˆ¬",
            "ai development": "AIä¸€èˆ¬",
            "ai innovation": "AIä¸€èˆ¬",
            "ai general": "AIä¸€èˆ¬",
            "machine learning": "AIä¸€èˆ¬",
            "ai applications": "AIä¸€èˆ¬",
            "ai tools": "AIä¸€èˆ¬",
            "ai systems": "AIä¸€èˆ¬",
            "ai solutions": "AIä¸€èˆ¬",
            "ai advancement": "AIä¸€èˆ¬",
            "ai breakthrough": "AIä¸€èˆ¬",
            "ai ethics": "AIä¸€èˆ¬",
            "ai safety": "AIä¸€èˆ¬",
            "ai regulation": "AIä¸€èˆ¬",
            "ai governance": "AIä¸€èˆ¬",
            
            # ç”ŸæˆAI
            "generative ai": "ç”ŸæˆAI",
            "generative artificial intelligence": "ç”ŸæˆAI",
            "gen ai": "ç”ŸæˆAI",
            "ai generation": "ç”ŸæˆAI",
            "content generation": "ç”ŸæˆAI",
            "ai creator": "ç”ŸæˆAI",
            "text generation": "ç”ŸæˆAI",
            "image generation": "ç”ŸæˆAI",
            "ai-generated": "ç”ŸæˆAI",
            "stable diffusion": "ç”ŸæˆAI",
            "dalle": "ç”ŸæˆAI",
            "dall-e": "ç”ŸæˆAI",
            "sora": "ç”ŸæˆAI",
            "video generation": "ç”ŸæˆAI",
            "music generation": "ç”ŸæˆAI",
            "code generation": "ç”ŸæˆAI",
            "copilot": "ç”ŸæˆAI",
            
            # LLM
            "llm": "LLM",
            "large language model": "LLM",
            "language model": "LLM",
            "gpt": "LLM",
            "chatgpt": "LLM",
            "claude": "LLM",
            "gemini": "LLM",
            "bert": "LLM",
            "transformer": "LLM",
            "nlp": "LLM",
            "natural language processing": "LLM",
            "gpt-4": "LLM",
            "gpt-3": "LLM",
            "llama": "LLM",
            "palm": "LLM",
            "bard": "LLM",
            "bing ai": "LLM",
            "chatbot": "LLM",
            "conversational ai": "LLM",
            "language understanding": "LLM",
            "text analysis": "LLM",
            "sentiment analysis": "LLM",
            
            # AI Startup
            "ai startup": "AI Startup",
            "ai company": "AI Startup",
            "ai venture": "AI Startup",
            "ai funding": "AI Startup",
            "ai investment": "AI Startup",
            "ai unicorn": "AI Startup",
            "openai": "AI Startup",
            "anthropic": "AI Startup",
            "midjourney": "AI Startup",
            "stability ai": "AI Startup",
            "hugging face": "AI Startup",
            "runway": "AI Startup",
            "perplexity": "AI Startup",
            "character.ai": "AI Startup",
            "jasper": "AI Startup",
            "ai acquisition": "AI Startup",
            "ai ipo": "AI Startup",
            "ai valuation": "AI Startup",
            
            # Deep Learning
            "deep learning": "Deep Learning",
            "neural network": "Deep Learning",
            "cnn": "Deep Learning",
            "rnn": "Deep Learning",
            "pytorch": "Deep Learning",
            "tensorflow": "Deep Learning",
            "keras": "Deep Learning",
            "computer vision": "Deep Learning",
            "image recognition": "Deep Learning",
            "object detection": "Deep Learning",
            "image classification": "Deep Learning",
            "facial recognition": "Deep Learning",
            "pattern recognition": "Deep Learning",
            "feature extraction": "Deep Learning",
            "model training": "Deep Learning",
            "backpropagation": "Deep Learning",
            "gradient descent": "Deep Learning",
            "convolutional": "Deep Learning",
            "lstm": "Deep Learning",
            "gru": "Deep Learning",
            "attention mechanism": "Deep Learning",
        }
        
        # ä»¶åã‹ã‚‰ã‚¿ã‚°ã‚’æŠ½å‡º
        for keyword, tag in tag_mapping.items():
            if keyword in subject_lower:
                if tag not in tags:
                    tags.append(tag)
        
        # ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€Œãã®ä»–ã€ã‚’è¨­å®š
        if not tags:
            tags.append("ãã®ä»–")
        
        logger.info(f"ä»¶å '{subject}' ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚¿ã‚°: {tags}")
        return tags
    
    def _authenticate_gmail(self):
        """Gmail APIã®èªè¨¼"""
        try:
            creds = None
            token_path = 'token.pickle'
            
            if os.path.exists(token_path):
                with open(token_path, 'rb') as token:
                    creds = pickle.load(token)
            
            if not creds or not creds.valid:
                if creds and creds.expired and creds.refresh_token:
                    creds.refresh(Request())
                else:
                    credentials_path = os.getenv('GMAIL_CREDENTIALS_PATH', 'credentials.json')
                    if not os.path.exists(credentials_path):
                        raise FileNotFoundError(f"èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ« {credentials_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    
                    flow = InstalledAppFlow.from_client_secrets_file(credentials_path, SCOPES)
                    creds = flow.run_local_server(port=0)
                
                with open(token_path, 'wb') as token:
                    pickle.dump(creds, token)
            
            return build('gmail', 'v1', credentials=creds)
        except Exception as e:
            logger.error(f"Gmailèªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def get_google_alerts_emails(self, date: Optional[datetime] = None, date_specified: bool = False, hours: int = 6) -> List[Dict]:
        """Google Alertsãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—
        
        Args:
            date: æ¤œç´¢å¯¾è±¡ã®æ—¥ä»˜ã€‚Noneã®å ´åˆã¯ç¾åœ¨æ™‚åˆ»ã‚’ä½¿ç”¨
            date_specified: æ—¥ä»˜ãŒæ˜ç¤ºçš„ã«æŒ‡å®šã•ã‚ŒãŸã‹ã©ã†ã‹
                - True: æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ã®å…¨æ—¥ (0:00-23:59)
                - False: éå»hoursæ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿
            hours: éå»ä½•æ™‚é–“ã®ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—ã™ã‚‹ã‹ï¼ˆdate_specified=Falseã®å ´åˆã®ã¿ä½¿ç”¨ï¼‰
        """
        if date is None:
            date = datetime.now()
        
        # JSTã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’è¨­å®š
        jst = pytz.timezone('Asia/Tokyo')
        
        # dateãŒnaiveã®å ´åˆã¯JSTã¨ã—ã¦æ‰±ã†
        if date.tzinfo is None:
            date = jst.localize(date)
        
        if date_specified:
            # æ—¥ä»˜ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼šãã®æ—¥ã®å…¨æ—¥ã‚’å¯¾è±¡
            start_date_jst = date.replace(hour=0, minute=0, second=0, microsecond=0)
            end_date_jst = start_date_jst + timedelta(days=1)
            logger.info(f"æ¤œç´¢æœŸé–“ (JST): {start_date_jst} ã‹ã‚‰ {end_date_jst} (æŒ‡å®šæ—¥å…¨æ—¥)")
        else:
            # æ—¥ä»˜ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼šéå»hoursæ™‚é–“ã‚’å¯¾è±¡
            end_date_jst = date
            start_date_jst = date - timedelta(hours=hours)
            logger.info(f"æ¤œç´¢æœŸé–“ (JST): {start_date_jst} ã‹ã‚‰ {end_date_jst} (éå»{hours}æ™‚é–“)")
        
        # Unix ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«å¤‰æ›
        start_timestamp = int(start_date_jst.timestamp())
        end_timestamp = int(end_date_jst.timestamp())
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›
        logger.info(f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {start_timestamp} ã‹ã‚‰ {end_timestamp}")
        
        # Google Alertsã®å·®å‡ºäººã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç¯„å›²ã§æ¤œç´¢
        query = f'from:googlealerts-noreply@google.com after:{start_timestamp} before:{end_timestamp}'
        logger.info(f"Gmailæ¤œç´¢ã‚¯ã‚¨ãƒª: {query}")
        
        # Gmail APIã‚¢ã‚¯ã‚»ã‚¹ã«ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ã‚’è¿½åŠ 
        import time
        retry_count = 3
        messages = []
        
        for attempt in range(retry_count):
            try:
                response = self.gmail_service.users().messages().list(
                    userId='me',
                    q=query,
                    maxResults=50  # Google Alertsã¯è¤‡æ•°ãƒ¡ãƒ¼ãƒ«ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§å¤šã‚ã«è¨­å®š
                ).execute()

                messages = response.get('messages', [])
                break  # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                
            except (HttpError, ConnectionError, TimeoutError, Exception) as error:
                if attempt < retry_count - 1:
                    wait_time = (attempt + 1) * 3  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•: 3ç§’, 6ç§’, 9ç§’
                    logger.warning(f'Gmailæ¤œç´¢ã‚¨ãƒ©ãƒ¼ (ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{retry_count}): {error}. {wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤...')
                    time.sleep(wait_time)
                else:
                    logger.error(f'Gmail APIã‚¨ãƒ©ãƒ¼: {error}. æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸ')
                    return []
        
        logger.info(f"Gmailæ¤œç´¢çµæœ: {len(messages)}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        
        if not messages:
                # ã‚ˆã‚Šåºƒã„ç¯„å›²ã§æ¤œç´¢ã—ã¦ã¿ã‚‹
                logger.info("ç¯„å›²ã‚’æ‹¡å¤§ã—ã¦Google Alertsãƒ¡ãƒ¼ãƒ«ã‚’æ¤œç´¢ä¸­...")
                broader_query = 'from:googlealerts-noreply@google.com'
                logger.info(f"æ‹¡å¤§æ¤œç´¢ã‚¯ã‚¨ãƒª: {broader_query}")
                
                broader_response = self.gmail_service.users().messages().list(
                    userId='me',
                    q=broader_query,
                    maxResults=10
                ).execute()
                
                broader_messages = broader_response.get('messages', [])
                logger.info(f"æ‹¡å¤§æ¤œç´¢çµæœ: {len(broader_messages)}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                
                if broader_messages:
                    logger.info("æœ€æ–°ã®Google Alertsãƒ¡ãƒ¼ãƒ«ã‚’ç¢ºèªä¸­...")
                    for msg in broader_messages[:3]:  # æœ€æ–°3ä»¶ã‚’ç¢ºèª
                        message = self.gmail_service.users().messages().get(
                            userId='me',
                            id=msg['id']
                        ).execute()
                        
                        # ãƒ¡ãƒ¼ãƒ«æ—¥æ™‚ã‚’å–å¾—
                        if 'internalDate' in message:
                            msg_timestamp = int(message['internalDate']) / 1000
                            msg_date = datetime.fromtimestamp(msg_timestamp, tz=pytz.timezone('Asia/Tokyo'))
                            logger.info(f"  ãƒ¡ãƒ¼ãƒ«ID: {msg['id']}, æ—¥æ™‚: {msg_date}")
                        
                        # ä»¶åã‚’å–å¾—
                        headers = message['payload'].get('headers', [])
                        subject = next((h['value'] for h in headers if h['name'] == 'Subject'), 'No Subject')
                        logger.info(f"  ä»¶å: {subject}")
                
                return []

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
        return messages
    
    def get_email_content_and_date(self, message_id: str, retry_count: int = 3) -> tuple[str, Optional[datetime], str]:
        """ãƒ¡ãƒ¼ãƒ«ã®æœ¬æ–‡ã€é…ä¿¡æ—¥æ™‚ã€ä»¶åã‚’å–å¾—ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰"""
        import time
        
        for attempt in range(retry_count):
            try:
                message = self.gmail_service.users().messages().get(
                    userId='me',
                    id=message_id
                ).execute()
                
                payload = message['payload']
                body = self._extract_body_from_payload(payload)
                
                # ãƒ¡ãƒ¼ãƒ«ä»¶åã‚’å–å¾—
                headers = payload.get('headers', [])
                subject = next((h['value'] for h in headers if h['name'] == 'Subject'), 'No Subject')
                
                # ãƒ¡ãƒ¼ãƒ«é…ä¿¡æ—¥æ™‚ã‚’å–å¾—
                email_date = None
                if 'internalDate' in message:
                    email_timestamp = int(message['internalDate']) / 1000
                    email_date = datetime.fromtimestamp(email_timestamp, tz=pytz.timezone('Asia/Tokyo'))
                    logger.info(f"  -> ãƒ¡ãƒ¼ãƒ«é…ä¿¡æ—¥æ™‚ã‚’å–å¾—: {email_date} (ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {message['internalDate']})")
                else:
                    logger.warning(f"  -> è­¦å‘Š: ãƒ¡ãƒ¼ãƒ«ã«internalDateãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ID: {message_id})")
                
                return body, email_date, subject
            
            except (HttpError, ConnectionError, TimeoutError, Exception) as error:
                if attempt < retry_count - 1:
                    wait_time = (attempt + 1) * 2  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•: 2ç§’, 4ç§’, 6ç§’
                    logger.warning(f'ãƒ¡ãƒ¼ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼ (ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{retry_count}): {error}. {wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤...')
                    time.sleep(wait_time)
                else:
                    logger.error(f'ãƒ¡ãƒ¼ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ID: {message_id}): {error}. æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸ')
                    
        return "", None, ""
    
    def _extract_body_from_payload(self, payload: Dict) -> str:
        """ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã‚’æŠ½å‡º"""
        body = ""
        
        if 'parts' in payload:
            for part in payload['parts']:
                if part['mimeType'] == 'text/html':
                    data = part['body']['data']
                    body = base64.urlsafe_b64decode(data).decode('utf-8')
                    break
                elif 'parts' in part:
                    body = self._extract_body_from_payload(part)
                    if body:
                        break
        elif payload['body'].get('data'):
            body = base64.urlsafe_b64decode(payload['body']['data']).decode('utf-8')
        
        return body
    
    def process_single_message(self, message: Dict, jst: pytz.timezone) -> List[Alert]:
        """å˜ä¸€ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã—ã¦ã‚¢ãƒ©ãƒ¼ãƒˆã‚’æŠ½å‡º"""
        message_id = message['id']
        self.safe_print(f"ãƒ¡ãƒ¼ãƒ«å‡¦ç†ä¸­: {message_id}")
        
        try:
            email_content, email_date, subject = self.get_email_content_and_date(message_id)
            
            if not email_content:
                self.safe_print(f"ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {message_id}")
                return []
            
            if email_date:
                self.safe_print(f"ãƒ¡ãƒ¼ãƒ«é…ä¿¡æ—¥æ™‚: {email_date}")
            
            self.safe_print(f"ãƒ¡ãƒ¼ãƒ«ä»¶å: {subject}")
            
            # ä»¶åã‹ã‚‰ã‚¿ã‚°ã‚’æŠ½å‡º
            tags = self.extract_tags_from_subject(subject)
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆæƒ…å ±ã‚’æŠ½å‡º
            alerts = self.parse_alerts_from_email(email_content)
            self.safe_print(f"æŠ½å‡ºã•ã‚ŒãŸã‚¢ãƒ©ãƒ¼ãƒˆæ•°: {len(alerts)}")
            
            # å„ã‚¢ãƒ©ãƒ¼ãƒˆã«ãƒ¡ãƒ¼ãƒ«é…ä¿¡æ—¥æ™‚ã¨ã‚¿ã‚°ã‚’è¨­å®š
            for alert in alerts:
                # æ—¥æ™‚è¨­å®š
                if email_date:
                    alert.date_processed = email_date.strftime('%Y-%m-%d')
                    self.safe_print(f"  -> ãƒ¡ãƒ¼ãƒ«é…ä¿¡æ—¥æ™‚ã‚’è¨­å®š: {email_date} -> {alert.date_processed}")
                else:
                    current_time = datetime.now(jst)
                    alert.date_processed = current_time.strftime('%Y-%m-%d')
                    self.safe_print(f"  -> è­¦å‘Š: ãƒ¡ãƒ¼ãƒ«é…ä¿¡æ—¥æ™‚ãŒå–å¾—ã§ããªã„ãŸã‚ç¾åœ¨æ™‚åˆ»ã‚’ä½¿ç”¨: {current_time} -> {alert.date_processed}")
                
                # ã‚¿ã‚°è¨­å®š
                alert.tags = tags.copy()  # ãƒªã‚¹ãƒˆã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
                self.safe_print(f"  -> ã‚¿ã‚°ã‚’è¨­å®š: {alert.tags}")
            
            return alerts
            
        except Exception as e:
            self.safe_print(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({message_id}): {e}")
            return []
    
    def process_messages_parallel(self, messages: List[Dict], max_workers: int = 1) -> List[Alert]:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸¦åˆ—å‡¦ç†ã—ã¦ã‚¢ãƒ©ãƒ¼ãƒˆã‚’æŠ½å‡º"""
        jst = pytz.timezone('Asia/Tokyo')
        all_alerts = []
        
        logger.info(f"ãƒ¡ãƒ¼ãƒ«ä¸¦åˆ—å‡¦ç†é–‹å§‹: {len(messages)}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’{max_workers}ä¸¦åˆ—ã§å‡¦ç†")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # å„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†ã‚’ä¸¦åˆ—ã§å®Ÿè¡Œ
            future_to_message = {
                executor.submit(self.process_single_message, message, jst): message 
                for message in messages
            }
            
            # å®Œäº†ã—ãŸå‡¦ç†ã‹ã‚‰çµæœã‚’å–å¾—
            for future in as_completed(future_to_message):
                try:
                    alerts = future.result()
                    all_alerts.extend(alerts)
                except Exception as e:
                    message = future_to_message[future]
                    logger.error(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ ({message['id']}): {e}")
        
        return all_alerts
    
    def parse_alerts_from_email(self, html_content: str) -> List[Alert]:
        """Google Alertsãƒ¡ãƒ¼ãƒ«HTMLã‹ã‚‰ã‚¢ãƒ©ãƒ¼ãƒˆæƒ…å ±ã‚’æŠ½å‡º"""
        soup = BeautifulSoup(html_content, 'html.parser')
        alerts = []
        
        # Google Alertsã®ãƒªãƒ³ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
        alert_links = soup.find_all('a', href=re.compile(r'https://www\.google\.com/url\?'))
        logger.info(f"Google Alertsãƒªãƒ³ã‚¯ã‚’ {len(alert_links)}å€‹ç™ºè¦‹")
        
        if not alert_links:
            logger.warning("Google Alertsãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        seen_urls = set()
        
        for link in alert_links:
            href = link.get('href', '')
            if not href:
                continue
            
            # Google URLã‹ã‚‰å®Ÿéš›ã®URLã‚’æŠ½å‡º
            try:
                # Google URLå½¢å¼: https://www.google.com/url?url=ACTUAL_URL&... ã¾ãŸã¯ ?q=ACTUAL_URL&...
                href_str = str(href)  # å‹ã‚’æ˜ç¤ºçš„ã«strã«å¤‰æ›
                parsed_url = urlparse(href_str)
                from urllib.parse import parse_qs
                query_params = parse_qs(parsed_url.query)
                
                actual_url = None
                # è¤‡æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
                for param in ['url', 'q']:
                    if param in query_params:
                        actual_url = query_params[param][0]
                        break
                
                if actual_url:
                    
                    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                    if actual_url in seen_urls:
                        continue
                    seen_urls.add(actual_url)
                    
                    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
                    title = link.get_text(strip=True)
                    if not title or len(title) < 5:
                        continue
                    
                    # ã‚½ãƒ¼ã‚¹ã‚’æŠ½å‡ºï¼ˆãƒªãƒ³ã‚¯ã®è¿‘ãã«ã‚ã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³æƒ…å ±ï¼‰
                    source = "Unknown"
                    try:
                        source = urlparse(actual_url).netloc
                    except Exception:
                        pass
                    
                    # ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æŠ½å‡ºï¼ˆãƒªãƒ³ã‚¯ã®å¾Œã«ã‚ã‚‹èª¬æ˜æ–‡ï¼‰
                    snippet = ""
                    parent = link.parent
                    if parent:
                        # è¦ªè¦ç´ ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æŠ½å‡º
                        parent_text = parent.get_text(strip=True)
                        # ã‚¿ã‚¤ãƒˆãƒ«ã‚ˆã‚Šå¾Œã®éƒ¨åˆ†ã‚’ã‚¹ãƒ‹ãƒšãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨
                        if title in parent_text:
                            snippet_parts = parent_text.split(title, 1)
                            if len(snippet_parts) > 1:
                                snippet = snippet_parts[1].strip()[:200]
                    
                    alert = Alert(
                        title=title,
                        url=actual_url,
                        source=source,
                        snippet=snippet,
                        date_processed=""  # ãƒ¡ãƒ¼ãƒ«é…ä¿¡æ—¥æ™‚ã¯å¾Œã§è¨­å®š
                    )
                    alerts.append(alert)
                    
            except Exception as e:
                logger.error(f"URLè§£æã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        return alerts
    
    def fetch_article_content(self, alert: Alert, retry_count: int = 3) -> str:
        """ã‚¢ãƒ©ãƒ¼ãƒˆURLã‹ã‚‰è¨˜äº‹ã®å†…å®¹ã‚’å–å¾—ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰"""
        import time
        import random
        
        # è¤‡æ•°ã®User-Agentã‚’ç”¨æ„
        user_agents = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:127.0) Gecko/20100101 Firefox/127.0',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'
        ]
        
        for attempt in range(retry_count):
            try:
                # ãƒ©ãƒ³ãƒ€ãƒ ãªUser-Agentã‚’é¸æŠ
                user_agent = random.choice(user_agents)
                
                # ã‚ˆã‚Šäººé–“ã‚‰ã—ã„ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®š
                headers = {
                    'User-Agent': user_agent,
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                    'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'DNT': '1',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                    'Sec-Fetch-Dest': 'document',
                    'Sec-Fetch-Mode': 'navigate',
                    'Sec-Fetch-Site': 'none',
                    'Cache-Control': 'max-age=0'
                }
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦Cookieã‚’ä¿æŒ
                session = requests.Session()
                session.headers.update(headers)
                
                response = session.get(alert.url, timeout=30, allow_redirects=True)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # è¨˜äº‹æœ¬æ–‡ã‚’æŠ½å‡ºã™ã‚‹è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
                content_selectors = [
                    'article',
                    '.post-content',
                    '.entry-content',
                    '.content',
                    '.article-body',
                    '.story-body',
                    '.article-content',
                    'main',
                    '.main-content',
                    '[role="main"]',
                    '.article-text',
                    '.post-body',
                    '.entry-content-wrap',
                    '.article-wrapper'
                ]
                
                article_text = ""
                for selector in content_selectors:
                    content_element = soup.select_one(selector)
                    if content_element:
                        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚¿ã‚°ã‚’é™¤å»
                        for script in content_element(['script', 'style', 'nav', 'header', 'footer', 'aside']):
                            script.decompose()
                        
                        article_text = content_element.get_text(separator=' ', strip=True)
                        if len(article_text) > 100:  # æœ‰æ„ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚ã‚‹å ´åˆ
                            break
                
                # è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                if not article_text or len(article_text) < 100:
                    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚¿ã‚°ã‚’é™¤å»
                    for script in soup(['script', 'style', 'nav', 'header', 'footer', 'aside']):
                        script.decompose()
                    article_text = soup.get_text(separator=' ', strip=True)
                
                # é•·ã™ãã‚‹å ´åˆã¯æœ€åˆã®3000æ–‡å­—ã«åˆ¶é™
                return article_text[:3000] if article_text else ""
                
            except requests.exceptions.HTTPError as e:
                if e.response.status_code in [403, 422, 429]:
                    # ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ç³»ã®ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
                    if attempt < retry_count - 1:
                        wait_time = (attempt + 1) * random.uniform(2, 5)  # ãƒ©ãƒ³ãƒ€ãƒ ãªå¾…æ©Ÿæ™‚é–“
                        logger.warning(f"è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼ ({alert.url}): {e.response.status_code} {e.response.reason}. {wait_time:.1f}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤...")
                        time.sleep(wait_time)
                        continue
                    else:
                        logger.error(f"è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼ ({alert.url}): {e.response.status_code} {e.response.reason}. ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’è¶…ãˆã¾ã—ãŸ")
                        return ""
                else:
                    # ãã®ä»–ã®HTTPã‚¨ãƒ©ãƒ¼ã¯å³åº§ã«çµ‚äº†
                    logger.error(f"è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼ ({alert.url}): {e.response.status_code} {e.response.reason}")
                    return ""
                    
            except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:
                if attempt < retry_count - 1:
                    wait_time = (attempt + 1) * 2
                    logger.warning(f"è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼ ({alert.url}): {e}. {wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤...")
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error(f"è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼ ({alert.url}): {e}. ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’è¶…ãˆã¾ã—ãŸ")
                    return ""
                    
            except Exception as e:
                if attempt < retry_count - 1:
                    wait_time = (attempt + 1) * 1.5
                    logger.warning(f"è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼ ({alert.url}): {e}. {wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤...")
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error(f"è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼ ({alert.url}): {e}. ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’è¶…ãˆã¾ã—ãŸ")
                    return ""
        
        return ""
    
    def fetch_articles_parallel(self, alerts: List[Alert], max_workers: int = 5) -> None:
        """è¤‡æ•°ã®ã‚¢ãƒ©ãƒ¼ãƒˆã®è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä¸¦åˆ—ã§å–å¾—"""
        logger.info(f"è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä¸¦åˆ—å–å¾—é–‹å§‹: {len(alerts)}ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’{max_workers}ä¸¦åˆ—ã§å‡¦ç†")
        
        def fetch_single_article(alert: Alert) -> None:
            """å˜ä¸€ã®è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã¦ã‚¢ãƒ©ãƒ¼ãƒˆã«è¨­å®š"""
            try:
                content = self.fetch_article_content(alert)
                # è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¢ãƒ©ãƒ¼ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ä¿å­˜ï¼ˆæ–°ã—ã„å±æ€§ã‚’è¿½åŠ ï¼‰
                if not hasattr(alert, 'article_content'):
                    alert.article_content = content
                else:
                    alert.article_content = content
                self.safe_print(f"  -> è¨˜äº‹å–å¾—å®Œäº†: {alert.url[:50]}...")
            except Exception as e:
                self.safe_print(f"  -> è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼: {alert.url}: {e}")
                alert.article_content = ""
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # å„ã‚¢ãƒ©ãƒ¼ãƒˆã®è¨˜äº‹å–å¾—ã‚’ä¸¦åˆ—ã§å®Ÿè¡Œ
            futures = [executor.submit(fetch_single_article, alert) for alert in alerts]
            
            # å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
            for future in as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    logger.error(f"è¨˜äº‹å–å¾—ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
    
    def generate_japanese_translation_and_summary(self, alert: Alert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã®æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ç¿»è¨³ã¨è¦ç´„ã‚’ç”Ÿæˆ"""
        try:
            # è¨˜äº‹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ï¼ˆä¸¦åˆ—å‡¦ç†ã§æ—¢ã«å–å¾—æ¸ˆã¿ã®å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ï¼‰
            if hasattr(alert, 'article_content'):
                article_content = alert.article_content
            else:
                article_content = self.fetch_article_content(alert)
            
            if not article_content:
                # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå–å¾—ã§ããªã„å ´åˆã¯ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’ä½¿ç”¨
                article_content = alert.snippet
            
            # Ollama APIã§ã‚¿ã‚¤ãƒˆãƒ«ç¿»è¨³ã¨è¦ç´„ç”Ÿæˆ
            prompt = f"""You are a professional translator and summarizer. Respond in JSON format.

Translate the following article title to Japanese and summarize the article content in Japanese (around 200 characters).

Original Title: {alert.title}
Source: {alert.source}
Original snippet: {alert.snippet}

Article Content:
{article_content}

---

Respond with a JSON object with two keys: 'japanese_title' and 'japanese_summary'.
Example:
{{
  "japanese_title": "ã“ã“ã«æ—¥æœ¬èªã®ã‚¿ã‚¤ãƒˆãƒ«",
  "japanese_summary": "ã“ã“ã«æ—¥æœ¬èªã®è¦ç´„"
}}
"""

            if self.ollama_client is None:
                raise ValueError("Ollama ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
            response = self.ollama_client.chat(
                model="gemma3:27b",
                messages=[{"role": "user", "content": prompt}],
                format="json"  # JSONãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–
            )

            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            if response.message and response.message.content:
                try:
                    result = json.loads(response.message.content)
                    alert.japanese_title = result.get('japanese_title', "ç¿»è¨³å¤±æ•—")
                    alert.japanese_summary = result.get('japanese_summary', "è¦ç´„å¤±æ•—")
                except json.JSONDecodeError:
                    logger.error(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {response.message.content}")
                    alert.japanese_title = "ç¿»è¨³å¤±æ•—"
                    alert.japanese_summary = "è¦ç´„å¤±æ•—"
            else:
                alert.japanese_title = "ç¿»è¨³å¤±æ•—"
                alert.japanese_summary = "ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒç©ºã§ã™"

        except Exception as e:
            logger.error(f"ç¿»è¨³ãƒ»è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({alert.title}): {e}")
            alert.japanese_title = "ç¿»è¨³å¤±æ•—"
            alert.japanese_summary = "è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
    
    def process_translations_parallel(self, alerts: List[Alert], max_workers: int = 2) -> None:
        """è¤‡æ•°ã®ã‚¢ãƒ©ãƒ¼ãƒˆã®ç¿»è¨³ãƒ»è¦ç´„ã‚’ä¸¦åˆ—ã§å‡¦ç†"""
        logger.info(f"ç¿»è¨³ãƒ»è¦ç´„ä¸¦åˆ—å‡¦ç†é–‹å§‹: {len(alerts)}ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’{max_workers}ä¸¦åˆ—ã§å‡¦ç†")
        
        def process_single_translation(alert: Alert) -> None:
            """å˜ä¸€ã®ã‚¢ãƒ©ãƒ¼ãƒˆã®ç¿»è¨³ãƒ»è¦ç´„ã‚’å‡¦ç†"""
            try:
                self.safe_print(f"  -> ç¿»è¨³ãƒ»è¦ç´„å‡¦ç†ä¸­: {alert.title[:50]}...")
                self.generate_japanese_translation_and_summary(alert)
                self.safe_print(f"  -> ç¿»è¨³ãƒ»è¦ç´„å®Œäº†: {alert.japanese_title[:30]}...")
            except Exception as e:
                self.safe_print(f"  -> ç¿»è¨³ãƒ»è¦ç´„ã‚¨ãƒ©ãƒ¼: {alert.title}: {e}")
                alert.japanese_title = "ç¿»è¨³å¤±æ•—"
                alert.japanese_summary = "è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # å„ã‚¢ãƒ©ãƒ¼ãƒˆã®ç¿»è¨³ãƒ»è¦ç´„ã‚’ä¸¦åˆ—ã§å®Ÿè¡Œ
            futures = [executor.submit(process_single_translation, alert) for alert in alerts]
            
            # å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
            for future in as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    logger.error(f"ç¿»è¨³ãƒ»è¦ç´„ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
    
    def save_to_notion(self, alert: Alert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆæƒ…å ±ã‚’Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        database_id = os.getenv('NOTION_DB_ID_GOOGLE_ALERTS')
        if not database_id:
            raise ValueError("NOTION_DB_ID_GOOGLE_ALERTSç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        try:
            if self.notion_client is None:
                raise ValueError("Notion ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
            # æ—¢å­˜ã®ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯
            existing = self.notion_client.databases.query(
                database_id=database_id,
                filter={
                    "property": "URL",
                    "url": {
                        "equals": alert.url
                    }
                }
            )

            if existing.get('results'):
                logger.info(f"  -> æ—¢ã«å­˜åœ¨ã™ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {alert.title}")
                return

            # æ–°è¦ãƒšãƒ¼ã‚¸ä½œæˆ
            logger.info(f"  -> Notionã«ä¿å­˜ã™ã‚‹æ—¥æ™‚: {alert.date_processed}")
            logger.info(f"  -> Notionã«ä¿å­˜ã™ã‚‹ã‚¿ã‚°: {alert.tags}")
            
            # ã‚¿ã‚°ã‚’Notionã®Multi-selectå½¢å¼ã«å¤‰æ›
            tags_property = {
                "multi_select": [
                    {"name": tag} for tag in alert.tags
                ]
            }
            
            if self.notion_client is None:
                raise ValueError("Notion ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
            self.notion_client.pages.create(
                parent={"database_id": database_id},
                properties={
                    "Title": {
                        "title": [
                            {
                                "text": {
                                    "content": alert.japanese_title
                                }
                            }
                        ]
                    },
                    "Original Title": { 
                        "rich_text": [
                            {
                                "text": {
                                    "content": alert.title
                                }
                            }
                        ]
                    },
                    "URL": {
                        "url": alert.url
                    },
                    "Source": {
                        "rich_text": [
                            {
                                "text": {
                                    "content": alert.source
                                }
                            }
                        ]
                    },
                    "Summary": {
                        "rich_text": [
                            {
                                "text": {
                                    "content": alert.japanese_summary
                                }
                            }
                        ]
                    },
                    "Snippet": {
                        "rich_text": [
                            {
                                "text": {
                                    "content": alert.snippet
                                }
                            }
                        ]
                    },
                    "Tags": tags_property,
                    "Date": {
                        "date": {
                            "start": alert.date_processed,
                            "time_zone": "Asia/Tokyo"
                        }
                    }
                }
            )

            logger.info(f"  -> ä¿å­˜å®Œäº†: {alert.title}")

        except Exception as e:
            logger.error(f"  -> Notionä¿å­˜ã‚¨ãƒ©ãƒ¼ ({alert.title}): {e}")
    
    def save_to_notion_parallel(self, alerts: List[Alert], max_workers: int = 3) -> List[Alert]:
        """è¤‡æ•°ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’Notionã«ä¸¦åˆ—ã§ä¿å­˜"""
        logger.info(f"Notionä¸¦åˆ—ä¿å­˜é–‹å§‹: {len(alerts)}ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’{max_workers}ä¸¦åˆ—ã§å‡¦ç†")
        
        saved_alerts = []
        
        def save_single_alert(alert: Alert) -> Alert:
            """å˜ä¸€ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’Notionã«ä¿å­˜"""
            try:
                self.safe_print(f"  -> Notionä¿å­˜ä¸­: {alert.title[:50]}...")
                self.save_to_notion(alert)
                self.safe_print(f"  -> Notionä¿å­˜å®Œäº†: {alert.title[:30]}...")
                return alert
            except Exception as e:
                self.safe_print(f"  -> Notionä¿å­˜ã‚¨ãƒ©ãƒ¼: {alert.title}: {e}")
                return alert  # ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚ã‚¢ãƒ©ãƒ¼ãƒˆã¯è¿”ã™
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # å„ã‚¢ãƒ©ãƒ¼ãƒˆã®Notionä¿å­˜ã‚’ä¸¦åˆ—ã§å®Ÿè¡Œ
            future_to_alert = {
                executor.submit(save_single_alert, alert): alert 
                for alert in alerts
            }
            
            # å®Œäº†ã—ãŸå‡¦ç†ã‹ã‚‰çµæœã‚’å–å¾—
            for future in as_completed(future_to_alert):
                try:
                    alert = future.result()
                    saved_alerts.append(alert)
                except Exception as e:
                    original_alert = future_to_alert[future]
                    logger.error(f"Notionä¿å­˜ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ ({original_alert.title}): {e}")
                    saved_alerts.append(original_alert)  # ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚ã‚¢ãƒ©ãƒ¼ãƒˆã¯è¿”ã™
        
        return saved_alerts
    
    def format_slack_messages(self, alerts: List[Alert], date: str, max_alerts_per_message: int = 12) -> List[str]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°ã®Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åˆ†å‰²ã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not alerts:
            return [f"*{date}ã®Google Alerts*\næœ¬æ—¥ã¯ã‚¢ãƒ©ãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"]
        
        messages = []
        total_alerts = len(alerts)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆã‚’æŒ‡å®šæ•°ãšã¤ã«åˆ†å‰²
        for i in range(0, total_alerts, max_alerts_per_message):
            batch = alerts[i:i + max_alerts_per_message]
            batch_num = (i // max_alerts_per_message) + 1
            total_batches = (total_alerts + max_alerts_per_message - 1) // max_alerts_per_message
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ä½œæˆ
            if total_batches > 1:
                header = f"*{date}ã®Google Alerts ({total_alerts}ä»¶) - Part {batch_num}/{total_batches}*\n\n"
            else:
                header = f"*{date}ã®Google Alerts ({total_alerts}ä»¶)*\n\n"
            
            message = header
            
            # ãƒãƒƒãƒå†…ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’è¿½åŠ 
            for j, alert in enumerate(batch, 1):
                alert_num = i + j  # å…¨ä½“é€šã—ã¦ã®ç•ªå·
                message += f"{alert_num}. *{alert.japanese_title or alert.title}*\n"
                message += f"   ğŸŒ {alert.source}\n"
                
                # ã‚¿ã‚°ã‚’è¡¨ç¤º
                if alert.tags:
                    tags_str = " | ".join(alert.tags)
                    message += f"   ğŸ·ï¸ {tags_str}\n"
                
                message += f"   ğŸ“„ {alert.japanese_summary}\n"
                message += f"   ğŸ”— <{alert.url}|è¨˜äº‹ã‚’èª­ã‚€>\n\n"
            
            # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆå®‰å…¨ã®ãŸã‚3500æ–‡å­—ã§åˆ¶é™ï¼‰
            if len(message) > 3500:
                logger.warning(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé•·ã™ãã¾ã™ ({len(message)}æ–‡å­—)ã€‚åˆ†å‰²æ•°ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
            
            messages.append(message)
        
        return messages
    
    def format_slack_message(self, alerts: List[Alert], date: str) -> str:
        """å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®å¾“æ¥ã®ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆå»ƒæ­¢äºˆå®šï¼‰"""
        messages = self.format_slack_messages(alerts, date, max_alerts_per_message=50)
        return messages[0] if messages else ""
    
    def send_to_slack(self, message: str) -> bool:
        """Slackã«æŠ•ç¨¿"""
        if not SLACK_WEBHOOK_URL:
            logger.error("SLACK_WEBHOOK_URL_GOOGLE_ALERTSç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        payload = {"text": message}
        
        try:
            response = requests.post(SLACK_WEBHOOK_URL, json=payload)
            if response.status_code == 200:
                logger.info("Slackã¸ã®é€ä¿¡ãŒå®Œäº†ã—ã¾ã—ãŸ")
                return True
            else:
                logger.error(f"Slackã¸ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"Slackã¸ã®é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def send_to_slack_batch(self, alerts: List[Alert], date: str) -> bool:
        """è¤‡æ•°ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’Slackã«åˆ†å‰²é€ä¿¡"""
        if not SLACK_WEBHOOK_URL:
            logger.error("SLACK_WEBHOOK_URL_GOOGLE_ALERTSç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ†å‰²
        messages = self.format_slack_messages(alerts, date)
        
        if not messages:
            logger.warning("é€ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“")
            return False
        
        success_count = 0
        total_messages = len(messages)
        
        logger.info(f"Slackã«{total_messages}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ†å‰²é€ä¿¡é–‹å§‹...")
        
        for i, message in enumerate(messages, 1):
            try:
                logger.info(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {i}/{total_messages} ã‚’é€ä¿¡ä¸­... ({len(message)}æ–‡å­—)")
                
                if self.send_to_slack(message):
                    success_count += 1
                    logger.info(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {i}/{total_messages} ã®é€ä¿¡å®Œäº†")
                else:
                    logger.error(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {i}/{total_messages} ã®é€ä¿¡å¤±æ•—")
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼šå„é€ä¿¡é–“ã«1ç§’é–“éš”ã‚’ç½®ã
                if i < total_messages:
                    import time
                    time.sleep(1)
                    
            except Exception as e:
                logger.error(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {i}/{total_messages} ã®é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        
        # çµæœãƒ­ã‚°
        if success_count == total_messages:
            logger.info(f"å…¨{total_messages}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ãŒå®Œäº†ã—ã¾ã—ãŸ")
            return True
        else:
            logger.warning(f"{success_count}/{total_messages}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ãŒå®Œäº†ã—ã¾ã—ãŸ")
            return success_count > 0
    
    def process_google_alerts(self, target_date: datetime, save_notion: bool = True, send_slack: bool = True, date_specified: bool = False, hours: int = 6):
        """Google Alertsã®å‡¦ç†ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
        date_str = target_date.strftime('%Y-%m-%d')
        if date_specified:
            logger.info(f"Google Alerts ({date_str}) ã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        else:
            logger.info(f"Google Alerts (éå»{hours}æ™‚é–“) ã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")

        # Slacké€ä¿¡ãŒæœ‰åŠ¹ãªå ´åˆã€ç’°å¢ƒå¤‰æ•°ã‚’ãƒã‚§ãƒƒã‚¯
        if send_slack and not SLACK_WEBHOOK_URL:
            raise ValueError("SLACK_WEBHOOK_URL_GOOGLE_ALERTSç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Slacké€ä¿¡ã‚’è¡Œã†å ´åˆã¯è¨­å®šã—ã¦ãã ã•ã„ã€‚")

        # æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ã®ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—
        messages = self.get_google_alerts_emails(target_date, date_specified, hours)

        if not messages:
            if date_specified:
                logger.warning(f"{date_str} ã®Google Alertsãƒ¡ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            else:
                logger.warning(f"éå»{hours}æ™‚é–“ã®Google Alertsãƒ¡ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return

        # å…¨ã¦ã®ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰å…¨ã¦ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ä¸¦åˆ—ã§æŠ½å‡º
        all_alerts = self.process_messages_parallel(messages)

        logger.info(f"{len(all_alerts)}ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’æ¤œå‡ºã—ã¾ã—ãŸ")

        if not all_alerts:
            logger.warning("ã‚¢ãƒ©ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return

        # è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä¸¦åˆ—ã§å–å¾—
        self.fetch_articles_parallel(all_alerts)

        # ç¿»è¨³ãƒ»è¦ç´„ã‚’ä¸¦åˆ—ã§å‡¦ç†
        self.process_translations_parallel(all_alerts)

        # Notionã«ä¸¦åˆ—ã§ä¿å­˜
        if save_notion:
            processed_alerts = self.save_to_notion_parallel(all_alerts)
        else:
            processed_alerts = all_alerts

        # Slackã«é€ä¿¡ï¼ˆåˆ†å‰²é€ä¿¡ã‚’ä½¿ç”¨ï¼‰
        if send_slack and processed_alerts:
            if date_specified:
                self.send_to_slack_batch(processed_alerts, date_str)
            else:
                self.send_to_slack_batch(processed_alerts, f"éå»{hours}æ™‚é–“")

        logger.info("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description='Google Alertsãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—ã—ã¦Notionã«ä¿å­˜ãŠã‚ˆã³Slackã«é€ä¿¡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä¸¡æ–¹å®Ÿè¡Œï¼‰')
    
    # æ—¥ä»˜/æ™‚é–“æŒ‡å®šã®ç›¸äº’æ’ä»–çš„ã‚°ãƒ«ãƒ¼ãƒ—
    time_group = parser.add_mutually_exclusive_group()
    time_group.add_argument(
        '--date',
        type=str,
        help='å–å¾—ã™ã‚‹æ—¥ä»˜ (YYYY-MM-DDå½¢å¼)ã€‚æŒ‡å®šã—ãŸå ´åˆã¯ãã®æ—¥ã®å…¨ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—',
        default=None
    )
    time_group.add_argument(
        '--hours',
        type=int,
        help='éå»ä½•æ™‚é–“ã®ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—ã™ã‚‹ã‹ã‚’æŒ‡å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 6æ™‚é–“ï¼‰',
        default=6
    )
    
    # é€ä¿¡å…ˆã®ç›¸äº’æ’ä»–çš„ã‚°ãƒ«ãƒ¼ãƒ—
    exclusive_group = parser.add_mutually_exclusive_group()
    exclusive_group.add_argument(
        '--slack',
        action='store_true',
        help='Slackã¸ã®é€ä¿¡ã®ã¿å®Ÿè¡Œï¼ˆNotionä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰',
        default=False
    )
    exclusive_group.add_argument(
        '--notion',
        action='store_true',
        help='Notionã¸ã®ä¿å­˜ã®ã¿å®Ÿè¡Œï¼ˆSlacké€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰',
        default=False
    )
    
    args = parser.parse_args()
    
    # æ—¥ä»˜ã®ãƒ‘ãƒ¼ã‚¹ã¨æ¤œè¨¼
    date_specified = False
    hours = 6  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    if args.date:
        try:
            target_date = datetime.strptime(args.date, '%Y-%m-%d')
            date_specified = True
        except ValueError:
            logger.error("ã‚¨ãƒ©ãƒ¼: æ—¥ä»˜ã¯ YYYY-MM-DD å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„ (ä¾‹: 2024-01-15)")
            return
    else:
        target_date = datetime.now()
        hours = args.hours  # --hoursã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯ãã®å€¤ã‚’ä½¿ç”¨
    
    # ãƒ•ãƒ©ã‚°ã«åŸºã¥ã„ã¦å‹•ä½œã‚’æ±ºå®š
    if args.slack:
        # --slackãƒ•ãƒ©ã‚°ãŒã‚ã‚‹å ´åˆï¼šSlacké€ä¿¡ã®ã¿
        save_notion = False
        send_slack = True
    elif args.notion:
        # --notionãƒ•ãƒ©ã‚°ãŒã‚ã‚‹å ´åˆï¼šNotionä¿å­˜ã®ã¿
        save_notion = True
        send_slack = False
    else:
        # ãƒ•ãƒ©ã‚°ãªã—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ï¼šä¸¡æ–¹å®Ÿè¡Œ
        save_notion = True
        send_slack = True
    
    try:
        processor = GoogleAlertsProcessor()
        processor.process_google_alerts(target_date, save_notion=save_notion, send_slack=send_slack, date_specified=date_specified, hours=hours)
    except Exception as e:
        logger.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        raise


if __name__ == "__main__":
    main()