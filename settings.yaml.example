# Minitools 設定ファイル
# このファイルを settings.yaml にコピーして使用してください
# セキュリティ関連の設定（APIキー等）は .env ファイルに記載してください

# ========================================
# LLM抽象化レイヤー設定
# ========================================
llm:
  # 使用するプロバイダー: "ollama" または "openai"
  provider: "ollama"

  # Ollama設定
  ollama:
    default_model: "gemma3:27b"
    base_url: "http://localhost:11434"
    models:
      scoring: "gemma3:27b"        # 重要度スコアリング用
      summarization: "gemma3:27b"  # 要約生成用

  # OpenAI設定（OPENAI_API_KEY環境変数が必要）
  openai:
    default_model: "gpt-4o-mini"
    models:
      scoring: "gpt-4o-mini"       # 重要度スコアリング用
      summarization: "gpt-4o-mini" # 要約生成用

  # Gemini設定（GEMINI_API_KEY環境変数が必要）
  gemini:
    default_model: "gemini-2.5-flash"

# ========================================
# Embedding設定（類似記事検出用）
# ========================================
embedding:
  # Embeddingプロバイダー: "ollama" または "openai"
  # OpenAIを推奨（Ollamaの場合は ollama pull nomic-embed-text が必要）
  provider: "openai"

  # Ollama設定
  ollama:
    model: "nomic-embed-text"

  # OpenAI設定
  openai:
    model: "text-embedding-3-small"

# ========================================
# Ollamaモデル設定（従来の翻訳・要約用）
# ========================================
models:
  # ArXiv論文、Google Alerts、Medium記事の翻訳・要約用
  # 高精度な処理が必要な場合は gemma3:27b を推奨
  translation: "gemma3:27b"
  summarization: "gemma3:27b"
  
  # YouTube動画の要約用（より軽量なモデル）
  youtube_summary: "gemma3:12b"

# ========================================
# 処理設定
# ========================================
processing:
  # 並列処理の最大数
  max_concurrent_articles: 10      # 同時に処理する記事の最大数
  max_concurrent_ollama: 3         # Ollama APIへの同時リクエスト数
  max_concurrent_notion: 3         # Notion APIへの同時リクエスト数
  max_concurrent_http: 10          # HTTPリクエストの同時接続数
  
  # リトライ設定
  retry_count: 3                   # リトライ回数
  retry_delay: 2                   # リトライ間隔（秒）

# ========================================
# 各ツールのデフォルト設定
# ========================================
defaults:
  # ArXiv論文検索
  arxiv:
    # デフォルトの検索キーワード
    keywords:
      - "LLM"
      - "(RAG OR FINETUNING OR AGENT)"
    days_before: 1                 # 何日前から検索するか
    max_results: 50                # 最大検索結果数
    
  # Google Alerts
  google_alerts:
    hours_back: 6                  # 過去何時間分のメールを取得するか
    max_alerts_per_message: 12     # Slackメッセージあたりの最大アラート数
    
  # Medium Daily Digest
  medium:
    fetch_today: true              # 今日のダイジェストを取得
    use_jina_reader: false         # Jina AI Readerを使用（falseの場合はメールのプレビューを使用）
    translate_clap_threshold: 100  # 自動翻訳の拍手数閾値
    translate_provider: ollama     # 翻訳LLMプロバイダー
    translate_model: gemma3:27b    # 翻訳モデル

  # YouTube要約
  youtube:
    output_dir: "outputs"          # 出力ディレクトリ
    whisper_model: "mlx-community/whisper-large-v3-turbo"  # Whisperモデル
    audio_quality: "192"           # 音声品質（kbps）
    temp_dir: "outputs/temp"       # 一時ファイルディレクトリ

  # Weekly Digest（週次AIダイジェスト）
  weekly_digest:
    days_back: 7                   # 過去何日分の記事を取得するか
    top_articles: 20               # 上位何件の記事を選出するか
    provider: "openai"             # デフォルトLLMプロバイダー（高速なバッチ処理のため）
    batch_size: 20                 # バッチスコアリングのサイズ
    # 類似記事除去設定
    deduplication:
      enabled: true                # 類似記事除去を有効にするか
      similarity_threshold: 0.85   # 類似度閾値（0.80-0.90推奨）
      buffer_ratio: 2.5            # 候補記事の倍率（top_articles * buffer_ratio）
      embedding_model: "nomic-embed-text"  # Embeddingモデル

  # X Trend Digest（Xトレンドダイジェスト）
  x_trend:
    max_trends: 10                   # 地域ごとの最大トレンド数
    tweets_per_trend: 20             # トレンドあたりのツイート取得件数
    tweets_per_keyword: 20           # キーワードあたりのツイート取得件数
    tweets_per_account: 20           # アカウントあたりのツイート取得件数
    provider: "gemini"               # デフォルトLLMプロバイダー
    keywords:                        # キーワード検索リスト
      - "Claude Code"
      - "AI Agent"
      - "LLM reasoning"
    watch_accounts:                  # 監視アカウントリスト（@なしのユーザー名）
      - "kaboratory"
      - "svpino"

  # ArXiv Weekly Digest（ArXiv論文週次ダイジェスト）
  arxiv_weekly:
    days_back: 7                   # 過去何日分の論文を取得するか
    top_papers: 10                 # 上位何件の論文を選出するか
    provider: "openai"             # デフォルトLLMプロバイダー（高速なバッチ処理のため）
    batch_size: 20                 # バッチスコアリングのサイズ
    trend_query: "AI machine learning latest trends breakthroughs"  # Tavilyトレンド検索クエリ

# ========================================
# ログ設定
# ========================================
logging:
  level: "INFO"                    # ログレベル: DEBUG, INFO, WARNING, ERROR, CRITICAL
  colored: true                    # カラー出力の有効/無効
  log_dir: "outputs/logs"          # ログファイルの保存先
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# ========================================
# Gmail設定
# ========================================
gmail:
  credentials_file: "credentials.json"  # 認証情報ファイル
  token_file: "token.pickle"            # トークンファイル
  scopes:
    - "https://www.googleapis.com/auth/gmail.readonly"

# ========================================
# 出力設定
# ========================================
output:
  # ファイル保存設定
  save_transcripts: true           # 文字起こしを保存
  save_summaries: true             # 要約を保存
  
  # Notion設定
  notion:
    batch_size: 10                 # バッチ処理のサイズ
    properties:
      title_max_length: 255        # タイトルの最大文字数
      summary_max_length: 2000     # 要約の最大文字数
      
  # Slack設定
  slack:
    max_message_length: 3500       # メッセージの最大文字数
    use_blocks: false              # Slack Blocksフォーマットを使用
    include_timestamps: true       # タイムスタンプを含める

# ========================================
# カスタムタグ設定（Google Alerts用）
# ========================================
tags:
  # Google Alertsの件名からタグを抽出するためのマッピング
  google_alerts:
    # AI一般
    - keywords: ["artificial intelligence", "ai technology", "machine learning"]
      tag: "AI一般"
    
    # 生成AI
    - keywords: ["generative ai", "gen ai", "stable diffusion", "dalle", "sora"]
      tag: "生成AI"
    
    # LLM
    - keywords: ["llm", "large language model", "gpt", "chatgpt", "claude", "gemini"]
      tag: "LLM"
    
    # AI Startup
    - keywords: ["ai startup", "ai company", "openai", "anthropic", "midjourney"]
      tag: "AI Startup"
    
    # Deep Learning
    - keywords: ["deep learning", "neural network", "pytorch", "tensorflow"]
      tag: "Deep Learning"